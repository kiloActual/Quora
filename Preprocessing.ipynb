{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apurv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\apurv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['what',\n",
       "  'nonsense',\n",
       "  'is',\n",
       "  'this',\n",
       "  'the',\n",
       "  'cold',\n",
       "  'war',\n",
       "  'is',\n",
       "  'over',\n",
       "  'marxism',\n",
       "  'failed',\n",
       "  'get',\n",
       "  'used',\n",
       "  'to',\n",
       "  'the',\n",
       "  'new',\n",
       "  'world',\n",
       "  'order',\n",
       "  'you',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'any',\n",
       "  'commie',\n",
       "  'left',\n",
       "  'to',\n",
       "  'fightoh',\n",
       "  'and',\n",
       "  'there',\n",
       "  'no',\n",
       "  'need',\n",
       "  'for',\n",
       "  'bloodshed',\n",
       "  'the',\n",
       "  'only',\n",
       "  'people',\n",
       "  'shooting',\n",
       "  'are',\n",
       "  'the',\n",
       "  'police'],\n",
       " ['britain',\n",
       "  'ha',\n",
       "  'no',\n",
       "  'equivalent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'national',\n",
       "  'guard',\n",
       "  'which',\n",
       "  'is',\n",
       "  'an',\n",
       "  'outgrowth',\n",
       "  'of',\n",
       "  'the',\n",
       "  'old',\n",
       "  'state',\n",
       "  'militiasthe',\n",
       "  'british',\n",
       "  'army',\n",
       "  'reserve',\n",
       "  'is',\n",
       "  'like',\n",
       "  'the',\n",
       "  'u',\n",
       "  'army',\n",
       "  'reserve',\n",
       "  'a',\n",
       "  'collection',\n",
       "  'of',\n",
       "  'partially',\n",
       "  'trained',\n",
       "  'troop',\n",
       "  'who',\n",
       "  'can',\n",
       "  'be',\n",
       "  'rapidly',\n",
       "  'called',\n",
       "  'up',\n",
       "  'in',\n",
       "  'case',\n",
       "  'of',\n",
       "  'emergency'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'way',\n",
       "  'too',\n",
       "  'many',\n",
       "  'kind',\n",
       "  'to',\n",
       "  'answer',\n",
       "  'that',\n",
       "  'question',\n",
       "  'it',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'and',\n",
       "  'ancient',\n",
       "  'continent',\n",
       "  'but',\n",
       "  'many',\n",
       "  'people',\n",
       "  'there',\n",
       "  'still',\n",
       "  'wear',\n",
       "  'their',\n",
       "  'traditional',\n",
       "  'clothing',\n",
       "  'for',\n",
       "  'important',\n",
       "  'event',\n",
       "  'such',\n",
       "  'a',\n",
       "  'wedding',\n",
       "  'and',\n",
       "  'some',\n",
       "  'still',\n",
       "  'havent',\n",
       "  'started',\n",
       "  'wearing',\n",
       "  'western',\n",
       "  'clothes',\n",
       "  'the',\n",
       "  'maasai',\n",
       "  'men',\n",
       "  'still',\n",
       "  'wear',\n",
       "  'bright',\n",
       "  'red',\n",
       "  'cloak',\n",
       "  'and',\n",
       "  'carry',\n",
       "  'a',\n",
       "  'spear'],\n",
       " ['because',\n",
       "  'arrest',\n",
       "  'is',\n",
       "  'not',\n",
       "  'the',\n",
       "  'same',\n",
       "  'a',\n",
       "  'trial',\n",
       "  'eönwë',\n",
       "  'arrested',\n",
       "  'morgoth',\n",
       "  'but',\n",
       "  'wa',\n",
       "  'not',\n",
       "  'authorized',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'his',\n",
       "  'fate',\n",
       "  'morgoth',\n",
       "  'had',\n",
       "  'to',\n",
       "  'be',\n",
       "  'judged',\n",
       "  'by',\n",
       "  'his',\n",
       "  'peer',\n",
       "  'ie',\n",
       "  'the',\n",
       "  'valar'],\n",
       " ['best',\n",
       "  'bet',\n",
       "  'is',\n",
       "  'to',\n",
       "  'use',\n",
       "  'your',\n",
       "  'chromosomal',\n",
       "  'sex',\n",
       "  'in',\n",
       "  'the',\n",
       "  'absence',\n",
       "  'of',\n",
       "  'other',\n",
       "  'data',\n",
       "  'that',\n",
       "  'will',\n",
       "  'avoid',\n",
       "  'confusion',\n",
       "  'it',\n",
       "  'possible',\n",
       "  'but',\n",
       "  'extremely',\n",
       "  'rare',\n",
       "  'to',\n",
       "  'be',\n",
       "  'an',\n",
       "  'xy',\n",
       "  'female',\n",
       "  'swyers',\n",
       "  'syndrome',\n",
       "  'if',\n",
       "  'you',\n",
       "  'had',\n",
       "  'that',\n",
       "  'you',\n",
       "  'would',\n",
       "  'probably',\n",
       "  'know',\n",
       "  'it',\n",
       "  'it',\n",
       "  'caused',\n",
       "  'by',\n",
       "  'a',\n",
       "  'damaged',\n",
       "  'y',\n",
       "  'chromosome'],\n",
       " ['god',\n",
       "  'no',\n",
       "  'what',\n",
       "  'a',\n",
       "  'ridiculous',\n",
       "  'idea',\n",
       "  'who',\n",
       "  'ha',\n",
       "  'led',\n",
       "  'the',\n",
       "  'nation',\n",
       "  'led',\n",
       "  'the',\n",
       "  'religion',\n",
       "  'and',\n",
       "  'owned',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'wealth',\n",
       "  'from',\n",
       "  'say',\n",
       "  'bc',\n",
       "  'to',\n",
       "  'the',\n",
       "  'present'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'none',\n",
       "  'they',\n",
       "  'are',\n",
       "  'simply',\n",
       "  'wrong',\n",
       "  'the',\n",
       "  'constitution',\n",
       "  'say',\n",
       "  'nothing',\n",
       "  'about',\n",
       "  'a',\n",
       "  'right',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'your',\n",
       "  'own',\n",
       "  'clothing',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'the',\n",
       "  'state',\n",
       "  'have',\n",
       "  'the',\n",
       "  'power',\n",
       "  'to',\n",
       "  'regulate',\n",
       "  'it'],\n",
       " ['some',\n",
       "  'other',\n",
       "  'answer',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'think',\n",
       "  'you',\n",
       "  'are',\n",
       "  'referring',\n",
       "  'to',\n",
       "  'the',\n",
       "  'heir',\n",
       "  'to',\n",
       "  'the',\n",
       "  'throne',\n",
       "  'but',\n",
       "  'such',\n",
       "  'a',\n",
       "  'person',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'monarch',\n",
       "  'before',\n",
       "  'they',\n",
       "  'are',\n",
       "  'crowned',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  'crown',\n",
       "  'prince',\n",
       "  'or',\n",
       "  'crown',\n",
       "  'princess'],\n",
       " ['wed',\n",
       "  'rather',\n",
       "  'have',\n",
       "  'leader',\n",
       "  'who',\n",
       "  'tell',\n",
       "  'u',\n",
       "  'comforting',\n",
       "  'lie',\n",
       "  'no',\n",
       "  'intelligence',\n",
       "  'is',\n",
       "  'required',\n",
       "  'for',\n",
       "  'that',\n",
       "  'in',\n",
       "  'fact',\n",
       "  'it',\n",
       "  'an',\n",
       "  'obstacle',\n",
       "  'ordinary',\n",
       "  'people',\n",
       "  'do',\n",
       "  'not',\n",
       "  'like',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'smarter',\n",
       "  'than',\n",
       "  'they',\n",
       "  'are',\n",
       "  'they',\n",
       "  'are',\n",
       "  'sure',\n",
       "  'that',\n",
       "  'smart',\n",
       "  'people',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'trick',\n",
       "  'them',\n",
       "  'or',\n",
       "  'cheat',\n",
       "  'them',\n",
       "  'somehow'],\n",
       " ['no',\n",
       "  'it',\n",
       "  'hasnt',\n",
       "  'marxism',\n",
       "  'wa',\n",
       "  'a',\n",
       "  'philosophy',\n",
       "  'of',\n",
       "  'history',\n",
       "  'and',\n",
       "  'economics',\n",
       "  'and',\n",
       "  'it',\n",
       "  'doesnt',\n",
       "  'apply',\n",
       "  'to',\n",
       "  'current',\n",
       "  'life',\n",
       "  'it',\n",
       "  'a',\n",
       "  'dead',\n",
       "  'duck'],\n",
       " ['because',\n",
       "  'they',\n",
       "  'might',\n",
       "  'learn',\n",
       "  'something',\n",
       "  'from',\n",
       "  'them',\n",
       "  'a',\n",
       "  'muslim',\n",
       "  'and',\n",
       "  'christian',\n",
       "  'they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'fear',\n",
       "  'the',\n",
       "  'dead',\n",
       "  'and',\n",
       "  'they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'of',\n",
       "  'reverence',\n",
       "  'or',\n",
       "  'worship',\n",
       "  'of',\n",
       "  'them',\n",
       "  'of',\n",
       "  'course',\n",
       "  'they',\n",
       "  'dont',\n",
       "  'want',\n",
       "  'anyone',\n",
       "  'digging',\n",
       "  'up',\n",
       "  'graf',\n",
       "  'of',\n",
       "  'their',\n",
       "  'immediate',\n",
       "  'ancestor',\n",
       "  'but',\n",
       "  'modern',\n",
       "  'egyptian',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'personal',\n",
       "  'connection',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ancient',\n",
       "  'dead',\n",
       "  'too',\n",
       "  'much',\n",
       "  'time',\n",
       "  'ha',\n",
       "  'passed'],\n",
       " ['certainly',\n",
       "  'but',\n",
       "  'it',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'get',\n",
       "  'the',\n",
       "  'attention',\n",
       "  'of',\n",
       "  'the',\n",
       "  'mass',\n",
       "  'they',\n",
       "  'would',\n",
       "  'rather',\n",
       "  'watch',\n",
       "  'an',\n",
       "  'exciting',\n",
       "  'conspiracy',\n",
       "  'theory',\n",
       "  'full',\n",
       "  'of',\n",
       "  'lie',\n",
       "  'on',\n",
       "  'youtube',\n",
       "  'than',\n",
       "  'read',\n",
       "  'a',\n",
       "  'carefully',\n",
       "  'researched',\n",
       "  'book'],\n",
       " ['no',\n",
       "  'it',\n",
       "  'madness',\n",
       "  'exposing',\n",
       "  'vulnerable',\n",
       "  'child',\n",
       "  'to',\n",
       "  'a',\n",
       "  'deadly',\n",
       "  'disease',\n",
       "  'and',\n",
       "  'forcing',\n",
       "  'them',\n",
       "  'to',\n",
       "  'go',\n",
       "  'it',\n",
       "  'barbaric'],\n",
       " ['no',\n",
       "  'what',\n",
       "  'idiot',\n",
       "  'told',\n",
       "  'you',\n",
       "  'that',\n",
       "  'have',\n",
       "  'you',\n",
       "  'been',\n",
       "  'watching',\n",
       "  'youtube',\n",
       "  'video',\n",
       "  'again']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "Df_pd = pd.read_csv(\"C:/Users/apurv/Desktop/Assignment1.csv\", encoding='cp1252')\n",
    "Df_pd\n",
    "Rev_list=Df_pd[\"Answers\"]\n",
    "def preprocess(text):\n",
    "    clean_data = []\n",
    "    for x in (text[:]): \n",
    "        new_text = re.sub('<.*?>', '', x)   # remove HTML tags\n",
    "        new_text = re.sub(r'[^\\w\\s]', '', new_text) # remove punc.\n",
    "        new_text = re.sub(r'\\d+','',new_text)# remove numbers\n",
    "        new_text = new_text.lower() # lower case, .upper() for upper          \n",
    "        if new_text != '':\n",
    "            clean_data.append(new_text)\n",
    "    return clean_data\n",
    "def tokenization_w(words):\n",
    "    w_new = []\n",
    "    for w in (words[:]):\n",
    "        w_token = word_tokenize(w)\n",
    "        if w_token != '':\n",
    "            w_new.append(w_token)\n",
    "    return w_new\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatization(words):\n",
    "    new = []\n",
    "    for i in range(len(Rev_list)):\n",
    "        lem_words = [lemmatizer.lemmatize(x) for x in (words[:][i])]\n",
    "        new.append(lem_words)\n",
    "    return new\n",
    "clean_list = preprocess(Rev_list) #removes punctuation, see above\n",
    "clean_words = tokenization_w(clean_list) # word tokenization\n",
    "lem = lemmatization(clean_words)\n",
    "lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
